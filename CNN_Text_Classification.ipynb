{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SDS 203 Deep Learning Project \n",
    "IMT - Atlantique <br>\n",
    "Brest, France <br>\n",
    "\n",
    "Author : Raymond Klutse <br>\n",
    "Date : 21 June , 2019\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text classification has become a very important part of Natural Language Processing. It is often used for Sentiment Analysis and Identification of harmful messages on social media networks such as Twitter and Facebook. Achieving this aim is quite difficult hence the numerous researches on going in this subject area. This project is a final semester project for SDS 203 Deep Learning at IMT - Atlantique, based on an article by Zhang et al on [Character-level Convolutional Networks for Text Classification](https://papers.nips.cc/paper/5782-character-level-convolutional-networks-for-text-classification.pdf) , where convolutional networks were used to extract information from text data. Application of CNN to text is often done at the word level where words are vectorised in order for them to be fed into a neural network for training. In this article, Zhang et al propose vectorisation of text at the character level instead of the word level. This allows the CNN to gain more insight about the data. Also,this CNNN does not require any prior knowledge of the words used to train the networks.  <br> The implementation of this project follows a [CRISP-DM](https://docs.oracle.com/cd/B19306_01/datamine.102/b14339/5dmtasks.htm) Methodology for data mining.<br> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this project is to implement a Convolutional Neural Network for Text Classification. The model trained should be able to classify new data into one of two classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first import the necessary libraries that will be to understand and explore the data.Data used to implement the solution provided in the article  is available on [Amazon Reviews for Sentiment Analysis](https://www.kaggle.com/bittlingmayer/amazonreviews). Data available from amazon reviews is divided into train and test data. We will first load both datasets into different dataframes using pandas. A label label__1  represent negative reviews whilst label__2 represent positive reviews "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset shape :  (3600000, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>__label__2 Stuning even for the non-gamer: Thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>__label__2 The best soundtrack ever to anythin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>__label__2 Amazing!: This soundtrack is my fav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>__label__2 Excellent Soundtrack: I truly like ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>__label__2 Remember, Pull Your Jaw Off The Flo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  __label__2 Stuning even for the non-gamer: Thi...\n",
       "1  __label__2 The best soundtrack ever to anythin...\n",
       "2  __label__2 Amazing!: This soundtrack is my fav...\n",
       "3  __label__2 Excellent Soundtrack: I truly like ...\n",
       "4  __label__2 Remember, Pull Your Jaw Off The Flo..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read train dataset\n",
    "train = pd.read_csv('amazonreviews/train.ft.txt',delimiter=\"\\n\",header=None)\n",
    "print(\"Train dataset shape : \",train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset shape :  (400000, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>__label__2 Great CD: My lovely Pat has one of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>__label__2 One of the best game music soundtra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>__label__1 Batteries died within a year ...: I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>__label__2 works fine, but Maha Energy is bett...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>__label__2 Great for the non-audiophile: Revie...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  __label__2 Great CD: My lovely Pat has one of ...\n",
       "1  __label__2 One of the best game music soundtra...\n",
       "2  __label__1 Batteries died within a year ...: I...\n",
       "3  __label__2 works fine, but Maha Energy is bett...\n",
       "4  __label__2 Great for the non-audiophile: Revie..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read test dataset\n",
    "test = pd.read_csv('amazonreviews/test.ft.txt',delimiter=\"\\n\",header=None)\n",
    "print(\"Test dataset shape : \",test.shape)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe from the dataframe that each row consists of a label and its respective review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the article,an alphabet set of 70 were used to represent characters in a text review. From observation, there was a duplicate of character '-' in the alphabet set , hence my implementation used 69 alphabets. We first prepare the alphabets that are going to be used in the model. Also, we will create functions to clean our text data and separated model from text review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alphabets used for one hot encoding\n",
    "ascii_lowercase = 'abcdefghijklmnopqrstuvwxyz'\n",
    "digits = '0123456789'\n",
    "punctuation = '-,;.!?:\"/\\|_\\'@#$%^&*~`+=<>[](){}'\n",
    "whitespace = '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abcdefghijklmnopqrstuvwxyz\n",
      "Number of english letters : 26\n",
      "0123456789\n",
      "Number of digits : 10\n",
      "-,;.!?:\"/\\|_'@#$%^&*~`+=<>[](){}\n",
      "Number of punctuations : 32\n",
      "\n",
      "\n",
      "Number of whitespace : 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(ascii_lowercase), print(\"Number of english letters :\",len(ascii_lowercase))\n",
    "\n",
    "print(digits), print(\"Number of digits :\",len(digits))\n",
    "\n",
    "print(punctuation), print(\"Number of punctuations :\",len(punctuation))\n",
    "\n",
    "print(whitespace), print(\"Number of whitespace :\",len(whitespace))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of alphabet : 69\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['!', '?', ':', '\"', '/', '\\\\', '|', '_', \"'\", '@']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "alphabet = list(itertools.chain(ascii_lowercase,digits, punctuation , whitespace))\n",
    "print(\"Size of alphabet :\",len(alphabet))\n",
    "alphabet[40:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#method to clean up string data\n",
    "import re\n",
    "def clean_str(string):\n",
    "    s = string.replace(\" \", \"\")\n",
    "    #s = re.sub(r\"[\\t]\", \"\", string)\n",
    "    return s.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#method to convert label into a binary value\n",
    "def convertlabeltobinary(label):\n",
    "    label = 0 if label == '__label__1' else 1\n",
    "    return label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now split our text into label and text and store it in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [__label__2, Stuning even for the non-gamer: T...\n",
       "1    [__label__2, The best soundtrack ever to anyth...\n",
       "2    [__label__2, Amazing!: This soundtrack is my f...\n",
       "3    [__label__2, Excellent Soundtrack: I truly lik...\n",
       "4    [__label__2, Remember, Pull Your Jaw Off The F...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.loc[:,0].str.split(' ', 1)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame(list(train),columns = ['label','text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>__label__1</td>\n",
       "      <td>Rushed and incomplete: After reading this book...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>__label__2</td>\n",
       "      <td>Superb Yet Darker: Now if you like me blast Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>__label__1</td>\n",
       "      <td>Two Serious Flaws: I also found the the displa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>__label__2</td>\n",
       "      <td>very good book for young readers: THis was a v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>__label__2</td>\n",
       "      <td>Amazing second album from Billy Talent: Billy ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        label                                               text\n",
       "0  __label__1  Rushed and incomplete: After reading this book...\n",
       "1  __label__2  Superb Yet Darker: Now if you like me blast Th...\n",
       "2  __label__1  Two Serious Flaws: I also found the the displa...\n",
       "3  __label__2  very good book for young readers: THis was a v...\n",
       "4  __label__2  Amazing second album from Billy Talent: Billy ..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "train= shuffle(train)\n",
    "train = train.reset_index(drop=True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then read the label column and apply the binary function to it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = train.loc[0:30000,'label'].apply(lambda x:convertlabeltobinary(x))\n",
    "train_label = train_label.reset_index(drop=True)\n",
    "train_label = pd.DataFrame(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train label dataset shape :  (30001, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label\n",
       "0      0\n",
       "1      1\n",
       "2      0\n",
       "3      1\n",
       "4      1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Train label dataset shape : \",train_label.shape)\n",
    "train_label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30001.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.501250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              label\n",
       "count  30001.000000\n",
       "mean       0.501250\n",
       "std        0.500007\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        1.000000\n",
       "75%        1.000000\n",
       "max        1.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    15038\n",
       "0    14963\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now read the text column and apply the clean function to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = train.loc[0:30000,'text'].apply(lambda x:clean_str(x))\n",
    "train_text = train_text.reset_index(drop=True)\n",
    "train_text = pd.DataFrame(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train text dataset shape : \",train_text.shape)\n",
    "train_text.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order for the network to function properly, we need to feed it numeric data. In view of this, we vectorise our text data. [One hot encoding](http://www.insightsbot.com/blog/zuyVu/python-one-hot-encoding-with-pandas-made-simple) is applied on characters in the alphabet set where the length of each encoded character is the length of the alphabet ,which in our case is 69. <br>\n",
    "In order for the model to capture enough insight from the data, the data samples must be of equal sizes. The maximum length of a review text is 1014. In order to acheive this, we pad all text reviews that are lower than this number with zeros.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#method to create padding vector\n",
    "def zerolistmaker(n):\n",
    "    listofzeros = [0] * n\n",
    "    return listofzeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#method to pad vector\n",
    "def pad_vector(vector):\n",
    "    while len(vector) < 1014 : vector.append(zerolistmaker(69))\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#method to vectorise text\n",
    "import string\n",
    "def string_vectorizer(string):\n",
    "    vector = [[0 if char != letter else 1 for char in alphabet ] for letter in string]\n",
    "    #vector = pd.get_dummies(pd.Series(list(string)).astype('category', categories=alphabet)).values.tolist()\n",
    "    vector = pad_vector(vector)\n",
    "    return np.asarray(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now vectorise out text using one hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text_vec = train_text.loc[0:,'text'].apply(lambda x : string_vectorizer(x))\n",
    "train_text_vec = pd.DataFrame(train_text_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train text vector shape : \",train_text.shape)\n",
    "train_text_vec.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We store the vectorised train text and our binary label in a new data frame. We then split our train data into train and validation data (30% of training data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_numeric = pd.concat([train_label,train_text_vec], axis=1)\n",
    "print(\"Train numeric shape : \",train_numeric.shape)\n",
    "train_numeric.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#method to split train and validation \n",
    "def validation_train_split(train,validation_size):\n",
    "    validation = train.iloc[validation_size:,:]\n",
    "    validation = validation.reset_index(drop=True)\n",
    "    train_size = validation_size -1\n",
    "    train = train.iloc[0:train_size,:]\n",
    "    return train,validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_numeric= shuffle(train_numeric)\n",
    "train_numeric = train_numeric.reset_index(drop=True)\n",
    "\n",
    "train_numeric,validation_numeric = validation_train_split(train_numeric,26001)\n",
    "print(\"Train numeric shape : \",train_numeric.shape)\n",
    "train_numeric.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the encoded text is stored in x_train for the network and their repsective labels are stored in y_train. The shape is in the form of (samples,sample rows, sample columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "x_train = np.stack(train_numeric.loc[:,'text'])\n",
    "y_train = list(train_numeric.loc[:,'label'])\n",
    "#y_train = to_categorical(y_train)\n",
    "print('X Training data shape:' ,x_train.shape)\n",
    "print('Y Training data shape:',len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Validation numeric shape : \",validation_numeric.shape)\n",
    "validation_numeric.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the encoded text is stored in x_validation for the network and their repsective labels are stored in y_validation. The shape is in the form of (samples,sample rows, sample columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_validation = np.stack(validation_numeric.loc[0:,'text'])\n",
    "y_validation = list(validation_numeric.loc[0:,'label'])\n",
    "print('X Validation data shape:' ,x_validation.shape)\n",
    "print('Y Validation data shape:',len(y_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now prepare the test data by performing the same functions applied to the train and validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.loc[:,0].str.split(' ', 1)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame(list(test),columns = ['label','text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test data shape : \",test.shape)\n",
    "test= shuffle(test)\n",
    "test = test.reset_index(drop=True)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label = test.loc[0:3000,'label'].apply(lambda x:convertlabeltobinary(x))\n",
    "test_label = test_label.reset_index(drop=True)\n",
    "test_label = pd.DataFrame(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test label shape : \",test_label.shape)\n",
    "test_label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = test.loc[0:3000,'text'].apply(lambda x:clean_str(x))\n",
    "test_text = test_text.reset_index(drop=True)\n",
    "test_text = pd.DataFrame(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test text shape : \",test_text.shape)\n",
    "test_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text_vec = test_text.loc[0:,'text'].apply(lambda x : string_vectorizer(x))\n",
    "test_text_vec = pd.DataFrame(test_text_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test text shape : \",test_text_vec.shape)\n",
    "test_text_vec.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_numeric = pd.concat([test_label,test_text_vec], axis=1)\n",
    "print(\"Test numeric shape : \",test_numeric.shape)\n",
    "test_numeric.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "x_test = np.stack(test_numeric.loc[:,'text'])\n",
    "x_test \n",
    "y_test = list(test_numeric.loc[:,'label'])\n",
    "#y_train = to_categorical(y_train)\n",
    "print('X Test data shape:' ,x_test.shape)\n",
    "print('Y Test data shape:',len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradients are obtained by back-propagation in order to perform optimization. \n",
    "\n",
    "One key module that helped us to train deeper models is temporal max-pooling.\n",
    "\n",
    "The non-linearity used in our model is the rectifier or thresholding function \n",
    "\n",
    "The algorithm used is stochastic gradient descent (SGD) with a minibatch of size 128, using momentum 0.9 and initial step size 0.01 which is halved every 3 epoches for 10 times\n",
    "\n",
    "Each epoch takes a fixed number of random training samples uniformly sampled across classe\n",
    "\n",
    "Our models accept a sequence of encoded characters as input.\n",
    "\n",
    "Each character is quantized using one-hot-encoding\n",
    "\n",
    "The alphabet used in all of our models consists of 70 characters, including 26 english letters, 10 digits, 33 other characters and the new line character. The non-space characters are:\n",
    "               abcdefghijklmnopqrstuvwxyz0123456789\n",
    "               -,;.!?:’’’/\\|_@#$%ˆ&* ̃‘+-=<>()[]{}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Building the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.activations import relu\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Embedding, Flatten, Dropout, concatenate\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "input_dim = x_train[0].shape\n",
    "print('Input Shape :' ,input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "input_layer = Input(shape = input_dim)\n",
    "\n",
    "cov_1 = Conv1D(filters=256, kernel_size=7, strides=1,activation='relu')(input_layer)\n",
    "pool_1= MaxPooling1D(pool_size=3)(cov_1)\n",
    "\n",
    "cov_2 = Conv1D(filters=256, kernel_size=7,strides=1,activation='relu')(pool_1)\n",
    "pool_2= MaxPooling1D(pool_size=3)(cov_2)\n",
    "\n",
    "cov_3 =Conv1D(filters=256, kernel_size=3,strides=1,activation='relu')(pool_2)\n",
    "\n",
    "cov_4 =Conv1D(filters=256, kernel_size=3,strides=1,activation='relu')(cov_3)\n",
    "\n",
    "cov_5 =Conv1D(filters=256, kernel_size=3,strides=1,activation='relu')(cov_4)\n",
    "\n",
    "cov_6 =Conv1D(filters=256, kernel_size= 3,strides=1,activation='relu')(cov_5)\n",
    "pool_6= MaxPooling1D(pool_size= 3)(cov_6)\n",
    "\n",
    "flat = Flatten()(pool_6)\n",
    "\n",
    "dense_1 = Dense(1024, activation='relu')(flat)\n",
    "drop_1 = Dropout(0.5)(dense_1 )\n",
    "\n",
    "dense_2 = Dense(1024, activation='relu')(drop_1)\n",
    "drop_2 = Dropout(0.5)(dense_2)\n",
    "\n",
    "dense_3 = Dense(1, activation='sigmoid')(drop_2)\n",
    "\n",
    "model = Model(inputs= input_layer,outputs=dense_3)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Loss function for binary classification](https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/) <br>\n",
    "[Choosing batch size](https://arxiv.org/pdf/1609.04836v1.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD, Adam\n",
    "learning_rate = 0.01\n",
    "epochs=10\n",
    "batch_size=128\n",
    "decay_rate = learning_rate / epochs\n",
    "momentum = 0.9\n",
    "\n",
    "sgd = SGD(lr=learning_rate , decay=decay_rate, momentum=momentum, nesterov=False)\n",
    "adam = Adam(lr=0.001) \n",
    "model.compile(loss='binary_crossentropy',optimizer= sgd, metrics=['accuracy'])\n",
    "decay_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for epoch in range(epochs):\n",
    "model_train = model.fit(x_train, y_train,\n",
    "                        epochs=epochs,\n",
    "                        batch_size= batch_size,\n",
    "                        validation_data=(x_validation, y_validation))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_eval = model.evaluate(x_validation, y_validation, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test loss:', validation_eval[0])\n",
    "print('Test accuracy:', validation_eval[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eval = model.evaluate(x_test, y_test,batch_size=128, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test loss:', test_eval[0])\n",
    "print('Test accuracy:', test_eval[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_53_perc.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('model_53_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loaded_model('model_53_perc.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_weights('model_53_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = model_train.history['acc']\n",
    "val_accuracy = model_train.history['val_acc']\n",
    "loss = model_train.history['loss']\n",
    "val_loss = model_train.history['val_loss']\n",
    "epochs = range(len(accuracy))\n",
    "plt.plot(epochs, accuracy, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a trained model to generate predictions on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)\n",
    "predicted_label = y_test[np.argmax(predictions[5])]\n",
    "print(\"File ->\", x_test[5], \"Predicted label: \" ,predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " x_test[5][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text.loc[5,'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label.loc[5,'label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deployment "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
